# app_dragdrop_excel_reports.py
# å¤‰æ›´ç‚¹: (1) PDFé–¢é€£ã‚³ãƒ¼ãƒ‰ã®å®Œå…¨å‰Šé™¤ (2) ãƒœã‚¿ãƒ³æ–‡è¨€/ã‚¿ã‚¤ãƒˆãƒ«UIã®ç°¡ç´ åŒ–
# å¼·åŒ–: (A) ãƒ˜ãƒƒãƒ€æ¤œå‡ºã§ã€Œæ‰•å‡ºæ•°ã€ã‚’æ•°é‡ã‚ˆã‚Šå„ªå…ˆ (B) LOTæŠ½å‡ºã§ã€ŒLot.ã€ã‚‚è¨±å¯
#       (C) è¡Œã‚­ãƒ£ãƒªãƒ¼ï¼‹é›†ç´„ãƒ­ã‚¸ãƒƒã‚¯ã«ã€Œã‚·ãƒªã‚¢ãƒ«ã®ã¿ã¶ã‚‰ä¸‹ãŒã‚Šï¼†Lot No.ç©ºã€ã®ç‰¹ä¾‹å¯¾å¿œ
#       (D) æ–°ã—ã„å‹ç•ªãƒ–ãƒ­ãƒƒã‚¯é–‹å§‹æ™‚ã« last_lotno / last_exp_norm ã‚’ç¢ºå®Ÿã«ãƒªã‚»ãƒƒãƒˆï¼ˆèª¤ã‚­ãƒ£ãƒªãƒ¼é˜²æ­¢ï¼‰
# ------------------------------------------------------------
# pip install streamlit pandas openpyxl requests
# å®Ÿè¡Œ: streamlit run app_dragdrop_excel_reports.py
# ------------------------------------------------------------
import io, os, re, time, datetime as dt
from typing import List, Tuple, Optional, Dict, Any

import streamlit as st
import pandas as pd
import requests
from openpyxl import load_workbook, Workbook
from openpyxl.utils import get_column_letter

HEADERS = ["å·¥ç¨‹å","LOT","å‹ç•ª","Lot No.","æ‰•å‡ºæ•°","æœ‰åŠ¹æœŸé™","ãƒ•ã‚¡ã‚¤ãƒ«å"]

# ===================== ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ =====================
def norm(s) -> str:
    if s is None: return ""
    return str(s).replace("\r"," ").replace("\n"," ").replace("ã€€"," ").strip()

def normalize_date(s: Optional[str]) -> Optional[str]:
    if not s: return None
    m = re.search(r"(\d{4})[./-](\d{1,2})[./-](\d{1,2})", s)
    if not m: return None
    y, mth, d = int(m.group(1)), int(m.group(2)), int(m.group(3))
    try:
        dtv = pd.Timestamp(year=y, month=mth, day=d)
        return f"{dtv.year}/{dtv.month}/{dtv.day}"
    except Exception:
        return None

def autosize(ws):
    for col in range(1, ws.max_column + 1):
        letter = get_column_letter(col)
        max_len = 0
        for cell in ws[letter]:
            val = "" if cell.value is None else str(cell.value)
            max_len = max(max_len, len(val))
        ws.column_dimensions[letter].width = min(max_len + 2, 80)

# æ•°é‡ã®å¼·åŒ–æ­£è¦åŒ–ï¼šæ•°å€¤å‹/å°æ•°/ã‚«ãƒ³ãƒ/å…¨è§’/å˜ä½ä»˜ãã‚‚OK
def _to_int_qty(q) -> Optional[int]:
    if q is None or (isinstance(q, float) and pd.isna(q)):
        return None
    if isinstance(q, (int, float)):
        return int(round(float(q)))
    s = str(q).strip()
    s = s.translate(str.maketrans("ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™ï¼ï¼ï¼Œ", "0123456789-.,")).replace(",", "")
    m = re.match(r"^\s*([+-]?\d+(?:\.\d+)?)", s)
    if not m:
        return None
    try:
        return int(round(float(m.group(1))))
    except Exception:
        return None

# NEW: ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ã€Œè¿”åº«ã€åˆ¤å®šï¼ˆExcelã«ã®ã¿é©ç”¨ï¼‰
def is_henko_from_name(filename_wo_ext: str) -> bool:
    return "è¿”åº«" in (filename_wo_ext or "")

# ===================== Excelãƒ˜ãƒƒãƒ€æ¤œå‡ºï¼ˆ2æ®µå¯¾å¿œï¼‰ =====================
HEADER_KEYS = {
    "model": ["å‹ç•ª","å“ç›®","å“ç•ª","å‹ å¼"],
    "lotno": ["Lot No","LotNo","LOT NO","ãƒ­ãƒƒãƒˆ","Lot"],
    # qty ã¯ã€Œæ‰•å‡ºæ•°ç³» ï¼ æ•°é‡ç³»ã€ã§å„ªå…ˆ
    "qty_hi": ["æ‰•å‡ºæ•°","æ‰•ã„å‡ºã—","æ‰•å‡º","å‡ºåº«","å‡ºæ•°"],
    "qty_lo": ["æ•°é‡","å€‹æ•°","æ•°"],
    "exp":   ["æœ‰åŠ¹æœŸé™","æœŸé™","è³å‘³æœŸé™","Exp","æœ‰åŠ¹æœŸæ—¥"],
}

def _n(cell):
    if pd.isna(cell): return ""
    return str(cell).strip().replace("ã€€","").replace("\n"," ").replace("\r"," ")

def detect_header(df: pd.DataFrame, scan_rows: int = 40) -> dict|None:
    def choose_col_by_priority(cells: list[str], high: list[str], low: list[str]) -> Optional[int]:
        lows = [c.lower() for c in cells]
        for kw in high:
            kwl = kw.lower()
            for c, txt in enumerate(lows):
                if kwl in txt: return c
        for kw in low:
            kwl = kw.lower()
            for c, txt in enumerate(lows):
                if kwl in txt: return c
        return None

    def first_hit(cells: list[str], keys: list[str]) -> Optional[int]:
        lows = [c.lower() for c in cells]
        for kw in keys:
            kwl = kw.lower()
            for c, txt in enumerate(lows):
                if kwl in txt: return c
        return None

    def hit_from_row(cells: list[str]) -> dict:
        hit={}
        lot_c = first_hit(cells, HEADER_KEYS["lotno"])
        if lot_c is not None: hit["lotno"] = lot_c
        exp_c = first_hit(cells, HEADER_KEYS["exp"])
        if exp_c is not None: hit["exp"] = exp_c
        model_c = first_hit(cells, HEADER_KEYS["model"])
        if model_c is not None: hit["model"] = model_c
        qty_c = choose_col_by_priority(cells, HEADER_KEYS["qty_hi"], HEADER_KEYS["qty_lo"])
        if qty_c is not None: hit["qty"] = qty_c
        if sum(1 for k in ["lotno","qty","exp"] if k in hit) >= 2 and "model" in hit:
            return hit
        return {}

    scan_rows = min(len(df), scan_rows)
    # 1æ®µ
    for r in range(scan_rows):
        row = [_n(x) for x in df.iloc[r,:].tolist()]
        if not any(row): continue
        hit = hit_from_row(row)
        if hit: return {"row": r, **hit}
    # 2æ®µï¼ˆä¸Šä¸‹ãƒãƒ¼ã‚¸ï¼‰
    for r in range(scan_rows-1):
        row1 = [_n(x) for x in df.iloc[r,:].tolist()]
        row2 = [_n(x) for x in df.iloc[r+1,:].tolist()]
        width = max(len(row1), len(row2))
        combo=[]
        for c in range(width):
            a = row1[c] if c < len(row1) else ""
            b = row2[c] if c < len(row2) else ""
            combo.append((a or b) if (a or b) else "")
        if not any(combo): continue
        hit = hit_from_row(combo)
        if hit: return {"row": r, **hit}
    return None

def extract_koutei_lot_from_sheet(df: pd.DataFrame, max_scan_rows:int=8, max_scan_cols:int=8) -> Tuple[Optional[str], Optional[str]]:
    koutei=None; lot=None
    rows=min(len(df),max_scan_rows); cols=min(df.shape[1],max_scan_cols)
    # å·¥ç¨‹åï¼ˆä¸Šéƒ¨ã®æœ€åˆã®éç©ºã‚»ãƒ«ï¼‰
    for r in range(rows):
        for c in range(cols):
            v=_n(df.iat[r,c])
            if v and not re.search(r"\b(lot|ãƒ­ãƒƒãƒˆ)\b", v, flags=re.I):
                koutei=v; break
        if koutei: break
    # LOTï¼ˆLot: / Lot. / ãƒ­ãƒƒãƒˆ: ã‚’è¨±å¯ï¼‰
    lot_pat = re.compile(r"(?:\bLot\b\.?|ãƒ­ãƒƒãƒˆ)\s*[ï¼š:\.\s]\s*([^\s]+)", re.I)
    for r in range(rows):
        for c in range(cols):
            s=_n(df.iat[r,c])
            if not s: continue
            m=lot_pat.search(s)
            if m: lot=m.group(1).strip(); break
        if lot: break
    return koutei, lot

# ===================== ã‚·ãƒ¼ãƒˆé¸æŠï¼ˆç·¨é›†ç”¨å„ªå…ˆãƒ»æ—¥ä»˜å„ªå…ˆãƒ»ç¢ºèªç³»é™¤å¤–ï¼‰ =====================
EXCLUDED_SHEET_PATTERNS = [
    r"åŸºæœ¬ã‚·ãƒ¼ãƒˆ", r"^ç¢ºèª", r"ç¢ºèªç”¨", r"ç¢ºèª\s*\(ç·¨é›†å¾Œ\)", r"ç¢ºèª\(ç·¨é›†å¾Œ\)",
    r"ãƒã‚§ãƒƒã‚¯", r"Check", r"DLç”¨"
]
DATE_SHEET_RE = re.compile(r"(?:^|\s)(\d{4})[./-](\d{1,2})[./-](\d{1,2})(?:\s|$)")

def choose_target_sheet(sheet_names: list[str]) -> tuple[str, str]:
    if "ç·¨é›†ç”¨" in sheet_names:
        return "ç·¨é›†ç”¨", "ç·¨é›†ç”¨ãŒæœ€å„ªå…ˆ"
    dated: list[tuple[dt.date, str]] = []
    for s in sheet_names:
        m = DATE_SHEET_RE.search(s)
        if m:
            y, mth, d = map(int, m.groups())
            try: dated.append((dt.date(y, mth, d), s))
            except: pass
    if dated:
        dated.sort(reverse=True)
        return dated[0][1], f"æ—¥ä»˜ã‚·ãƒ¼ãƒˆå„ªå…ˆï¼ˆæœ€æ–°={dated[0][0].isoformat()}ï¼‰"
    for s in sheet_names:
        if any(re.search(pat, s) for pat in EXCLUDED_SHEET_PATTERNS):
            continue
        return s, "é™¤å¤–ã‚’é™¤ã„ãŸå…ˆé ­ã‚·ãƒ¼ãƒˆ"
    return sheet_names[0], "ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆå…ˆé ­ï¼‰"

# ===================== Excelæ˜ç´°æŠ½å‡ºï¼ˆã‚­ãƒ£ãƒªãƒ¼ï¼‹é›†ç´„ï¼‹ç‰¹ä¾‹ï¼‹å¢ƒç•Œãƒªã‚»ãƒƒãƒˆï¼‰ =====================
def parse_excel_table(
    df: pd.DataFrame,
    header_map: dict,
    koutei: str,
    lot: str,
    file_label: str,
    qty_sign:int=1,
    require_lotno: bool=True,
    require_exp: bool=True,
) -> tuple[list[dict], dict]:
    """
    - ã€Œå‹ç•ªã‚»ãƒ«ãŒ1å›ã®ã¿ã€ã€ŒåŒä¸€Lot No.ãŒä¸‹ã«è¤‡æ•°è¡Œï¼ˆæ•°é‡ã ã‘1ãšã¤ç­‰ï¼‰ã€ã‚’ã‚µãƒãƒ¼ãƒˆã€‚
    - è¡Œèµ°æŸ»æ™‚ã« last_model / last_lotno / last_exp_norm ã‚’ã‚­ãƒ£ãƒªãƒ¼ã€‚
    - (model, lotno, exp_norm) å˜ä½ã§æ•°é‡ã‚’é›†ç´„ï¼ˆqty_signé©ç”¨å¾Œï¼‰â†’ å‡ºåŠ›ã€‚
    - ç‰¹ä¾‹: ã€Œã‚·ãƒªã‚¢ãƒ«ã ã‘ãŒä¸‹ã«ã¶ã‚‰ä¸‹ãŒã‚Šã€Lot No.æ¬„ãŒå…¨ä½“ã§ç©ºã€ã®ãƒ–ãƒ­ãƒƒã‚¯ã¯ã€
            Lot No.ç©ºã®ã¾ã¾ï¼ˆè¨±å®¹ï¼‰ã§å‹ç•ªè¡Œã®æ‰•å‡ºæ•°ã‚’1è¡Œã«ã¾ã¨ã‚ã¦å‡ºåŠ›ã€‚
            ï¼ˆUIã§Lot No.å¿…é ˆ=ONã§ã‚‚ãƒ–ãƒ­ãƒƒã‚¯å†…ã«Lot No.ãŒ1ã¤ã‚‚ç„¡ã‘ã‚Œã°è¨±å®¹ï¼‰
    - é‡è¦: æ–°ã—ã„â€œå‹ç•ªâ€ã‚’æ¤œçŸ¥ã—ãŸæ™‚ç‚¹ã§ã€last_lotno / last_exp_norm ã‚’å¿…ãš None ã«ãƒªã‚»ãƒƒãƒˆã—ã€
            å‰ãƒ–ãƒ­ãƒƒã‚¯ã®Lot/æœŸé™ãŒèª¤ã£ã¦ã‚­ãƒ£ãƒªãƒ¼ã•ã‚Œã‚‹ã®ã‚’é˜²æ­¢ã€‚
    """
    start=header_map["row"]+1
    mc,lc,qc,ec = header_map["model"],header_map["lotno"],header_map["qty"],header_map["exp"]
    sub=df.iloc[start:].copy().reset_index(drop=True)

    stats = {"ç©ºè¡Œ":0, "å‹ç•ªæ¬ è½":0, "LotNoæ¬ è½":0, "æ•°é‡ä¸æ­£":0, "æ•°é‡=0":0, "æ—¥ä»˜ä¸æ­£":0}
    agg: Dict[tuple, int] = {}

    last_model: Optional[str] = None
    last_lotno: Optional[str] = None
    last_exp_norm: Optional[str] = None

    def _cell(row, idx):
        return row.iloc[idx] if idx < len(row) else None

    def _str_or_none(v):
        s = None if pd.isna(v) or str(v).strip()=="" else str(v).strip()
        return s

    def has_any_lotno_until_next_model(start_i: int) -> bool:
        """ç¾åœ¨ã®è¡Œä»¥é™ã€æ¬¡ã®ãƒ¢ãƒ‡ãƒ«ãŒå‡ºã‚‹ã¾ã§ã®é–“ã«LotNoãŒ1ã¤ã§ã‚‚ã‚ã‚‹ã‹"""
        for j in range(start_i+1, len(sub)):
            rj = sub.iloc[j,:]
            model_j = _str_or_none(_cell(rj, mc))
            lotno_j = _str_or_none(_cell(rj, lc))
            if model_j:  # æ¬¡ã®ãƒ–ãƒ­ãƒƒã‚¯é–‹å§‹
                break
            if lotno_j:
                return True
        return False

    def lookahead_first_exp(start_i: int) -> Optional[str]:
        """ç¾åœ¨ã®è¡Œã‚’å«ã‚ã€æ¬¡ã®ãƒ¢ãƒ‡ãƒ«ãŒå‡ºã‚‹ã¾ã§ã«æœ€åˆã«è¦‹ã¤ã‹ã£ãŸæœŸé™ã‚’è¿”ã™"""
        for j in range(start_i, len(sub)):
            rj = sub.iloc[j,:]
            model_j = _str_or_none(_cell(rj, mc))
            if j > start_i and model_j:  # æ¬¡ãƒ–ãƒ­ãƒƒã‚¯ã«å…¥ã£ãŸã‚‰çµ‚äº†
                break
            expv_j = _str_or_none(_cell(rj, ec))
            exp_norm_j = normalize_date(expv_j) if expv_j else None
            if exp_norm_j:
                return exp_norm_j
        return None

    for i in range(len(sub)):
        row=sub.iloc[i,:]

        model_raw=_cell(row, mc)
        lotno_raw=_cell(row, lc)
        qty_raw  =_cell(row, qc)
        exp_raw  =_cell(row, ec)

        model = _str_or_none(model_raw)
        lotno = _str_or_none(lotno_raw)
        qty_i = _to_int_qty(qty_raw)
        exp_s = _str_or_none(exp_raw)
        exp_norm = normalize_date(exp_s) if exp_s else None

        # å®Œå…¨ç©ºè¡Œ
        if not any([model, lotno, (qty_i is not None), (exp_s is not None and exp_s!="")]):
            stats["ç©ºè¡Œ"] += 1
            continue

        # â˜… ãƒ–ãƒ­ãƒƒã‚¯å¢ƒç•Œæ¤œçŸ¥ï¼šã“ã®è¡Œã« model ãŒã‚ã‚Œã°æ–°ãƒ–ãƒ­ãƒƒã‚¯é–‹å§‹
        if model:
            last_model = model
            # å‰ãƒ–ãƒ­ãƒƒã‚¯ã®Lot/æœŸé™ã¯ã“ã“ã§ç¢ºå®Ÿã«æ¨ã¦ã‚‹ï¼ˆèª¤ã‚­ãƒ£ãƒªãƒ¼é˜²æ­¢ï¼‰
            last_lotno = None
            last_exp_norm = None

        # å…¥åŠ›ãŒã‚ã‚‹é …ç›®ã ã‘ last_* ã‚’æ›´æ–°
        if lotno: last_lotno = lotno
        if exp_norm: last_exp_norm = exp_norm

        cur_model = last_model
        cur_lotno = last_lotno
        cur_exp   = last_exp_norm

        if not cur_model:
            stats["å‹ç•ªæ¬ è½"] += 1
            continue

        # æ•°é‡ãƒã‚§ãƒƒã‚¯
        if qty_i is None:
            # æœŸé™ã ã‘ã‚„ã‚·ãƒªã‚¢ãƒ«è¡Œãªã©ã¯æ—¢ã«ã‚­ãƒ£ãƒªãƒ¼æ¸ˆã¿ãªã®ã§ã‚¨ãƒ©ãƒ¼ã«ã—ãªã„
            continue
        if qty_i == 0:
            stats["æ•°é‡=0"] += 1
            continue
        qty_i = abs(qty_i) * qty_sign

        # æœŸé™ãŒã“ã®æ™‚ç‚¹ã§æœªç¢ºå®šãªã‚‰ã€åŒãƒ–ãƒ­ãƒƒã‚¯å†…ã‹ã‚‰å…ˆèª­ã¿
        if require_exp and not cur_exp:
            peek_exp = lookahead_first_exp(i)
            if peek_exp:
                cur_exp = peek_exp
                last_exp_norm = peek_exp
            else:
                stats["æ—¥ä»˜ä¸æ­£"] += 1
                continue

        # Lot No.å¿…é ˆã ãŒã€ãƒ–ãƒ­ãƒƒã‚¯å†…ã«LotNoãŒ1ã¤ã‚‚ç„¡ã„=ã‚·ãƒªã‚¢ãƒ«ã ã‘ã®ç‰¹ä¾‹ã¯è¨±å®¹
        if require_lotno and not cur_lotno:
            if has_any_lotno_until_next_model(i):
                stats["LotNoæ¬ è½"] += 1
                continue
            else:
                cur_lotno = ""  # ç‰¹ä¾‹ï¼šç©ºã®ã¾ã¾å‡ºåŠ›

        key = (cur_model, cur_lotno or "", cur_exp or "")
        agg[key] = agg.get(key, 0) + qty_i

    out: List[Dict[str, Any]] = []
    for (model, lotno, exp_norm), qty_sum in agg.items():
        out.append({
            "å·¥ç¨‹å": koutei or "",
            "LOT": lot or "",
            "å‹ç•ª": model,
            "Lot No.": lotno,
            "æ‰•å‡ºæ•°": qty_sum,
            "æœ‰åŠ¹æœŸé™": exp_norm or "",
            "ãƒ•ã‚¡ã‚¤ãƒ«å": file_label
        })

    return out, stats

# ===================== é›†è¨ˆï¼ˆå“åã”ã¨ï¼å·¥ç¨‹ã”ã¨ï¼‰ =====================
def ensure_sheet(wb, name, headers):
    ws = wb[name] if name in wb.sheetnames else wb.create_sheet(name)
    if ws.max_row < 1 or all(ws.cell(row=1,column=i+1).value is None for i in range(len(headers))):
        for i,h in enumerate(headers,1): ws.cell(row=1,column=i).value = h
    return ws

def clear_sheet_body(ws):
    if ws.max_row > 1:
        ws.delete_rows(idx=2, amount=ws.max_row-1)

def read_sheet_as_records(ws) -> list[dict]:
    headers = [str(ws.cell(row=1, column=c).value or "").strip() for c in range(1, ws.max_column+1)]
    recs=[]
    for r in range(2, ws.max_row+1):
        row={}; empty=True
        for c,h in enumerate(headers,1):
            v = ws.cell(row=r, column=c).value
            if v not in (None,""): empty=False
            row[h]=v
        if not empty: recs.append(row)
    return recs

def build_name_map_from_master(wb) -> dict:
    if "å“åãƒã‚¹ã‚¿" not in wb.sheetnames:
        ws = wb.create_sheet("å“åãƒã‚¹ã‚¿")
        ws.cell(row=1, column=1, value="å“å")
        ws.cell(row=1, column=2, value="å‹ç•ª")
        return {}
    ws = wb["å“åãƒã‚¹ã‚¿"]
    mp={}
    for r in range(2, ws.max_row+1):
        pname = ws.cell(row=r, column=1).value
        model = ws.cell(row=r, column=2).value
        if model:
            mp[str(model).strip()] = ("" if pname in (None,"") else str(pname).strip())
    return mp

def refresh_reports_in_workbook(wb, edit_sheet_name="ç·¨é›†ç”¨"):
    if edit_sheet_name not in wb.sheetnames:
        return
    ws_edit = wb[edit_sheet_name]
    records = read_sheet_as_records(ws_edit)
    ws_by_item = ensure_sheet(wb, "å“åã”ã¨", ["å“å","å‹ç•ª","æ‰•å‡ºæ•°åˆè¨ˆ"])
    ws_by_proc = ensure_sheet(wb, "å·¥ç¨‹ã”ã¨", ["å·¥ç¨‹å","å“å","å‹ç•ª","æ‰•å‡ºæ•°åˆè¨ˆ"])
    clear_sheet_body(ws_by_item); clear_sheet_body(ws_by_proc)
    if not records:
        autosize(ws_by_item); autosize(ws_by_proc); return
    for rec in records:
        try: rec["æ‰•å‡ºæ•°"] = int(rec.get("æ‰•å‡ºæ•°",0))
        except: rec["æ‰•å‡ºæ•°"] = 0
    name_map = build_name_map_from_master(wb)
    sum_by_model={}
    for rec in records:
        model = str(rec.get("å‹ç•ª") or "").strip()
        if not model: continue
        sum_by_model[model] = sum_by_model.get(model,0) + rec["æ‰•å‡ºæ•°"]
    for model in sorted(sum_by_model.keys()):
        pname = name_map.get(model, "")
        ws_by_item.append([pname, model, sum_by_model[model]])
    autosize(ws_by_item)
    sum_by_proc_model={}
    for rec in records:
        proc  = str(rec.get("å·¥ç¨‹å") or "").strip()
        model = str(rec.get("å‹ç•ª") or "").strip()
        if not proc or not model: continue
        key=(proc, model)
        sum_by_proc_model[key] = sum_by_proc_model.get(key,0) + rec["æ‰•å‡ºæ•°"]
    for (proc, model) in sorted(sum_by_proc_model.keys(), key=lambda x:(x[0],x[1])):
        pname = name_map.get(model, "")
        ws_by_proc.append([proc, pname, model, sum_by_proc_model[(proc, model)]])
    autosize(ws_by_proc)

# ===================== â€œç·¨é›†ç”¨â€è¿½è¨˜ï¼‹ãƒ¬ãƒãƒ¼ãƒˆå†ä½œæˆ =====================
def update_workbook_with_rows(base_xlsx_bytes: bytes|None, rows: List[Dict[str,Any]], sheet_name:str="ç·¨é›†ç”¨") -> bytes:
    if base_xlsx_bytes:
        wb = load_workbook(io.BytesIO(base_xlsx_bytes))
    else:
        wb = Workbook()
        wb.active.title = sheet_name
        ws0 = wb[sheet_name]; ws0.append(HEADERS)
        ws_m = wb.create_sheet("å“åãƒã‚¹ã‚¿")
        ws_m.cell(row=1, column=1, value="å“å")
        ws_m.cell(row=1, column=2, value="å‹ç•ª")
        ensure_sheet(wb, "å“åã”ã¨", ["å“å","å‹ç•ª","æ‰•å‡ºæ•°åˆè¨ˆ"])
        ensure_sheet(wb, "å·¥ç¨‹ã”ã¨", ["å·¥ç¨‹å","å“å","å‹ç•ª","æ‰•å‡ºæ•°åˆè¨ˆ"])

    ws = wb[sheet_name] if sheet_name in wb.sheetnames else wb.create_sheet(sheet_name)
    if ws.max_row < 1 or all(ws.cell(row=1,column=c).value is None for c in range(1,len(HEADERS)+1)):
        for c,h in enumerate(HEADERS,1): ws.cell(row=1,column=c).value = h

    for r in rows:
        q = _to_int_qty(r.get("æ‰•å‡ºæ•°"))
        if q is None or q == 0:
            continue
        ws.append([r.get(h,"") for h in HEADERS])
    autosize(ws)
    refresh_reports_in_workbook(wb, edit_sheet_name=sheet_name)
    bio=io.BytesIO(); wb.save(bio); return bio.getvalue()

# ===================== Copilot Studioï¼ˆDirect Lineï¼‰é€£æºãƒ†ã‚¹ãƒˆ =====================
def copilot_directline_test(secret: str, test_message: str = "ping") -> tuple[bool, str]:
    try:
        headers = {"Authorization": f"Bearer {secret}", "Content-Type": "application/json"}
        r = requests.post("https://directline.botframework.com/v3/directline/conversations", headers=headers, json={})
        if r.status_code != 201:
            return False, f"start failed: {r.status_code} {r.text}"
        conv = r.json(); conv_id = conv.get("conversationId")
        if not conv_id:
            return False, "no conversationId"
        send_url = f"https://directline.botframework.com/v3/directline/conversations/{conv_id}/activities"
        payload = {"type":"message","from":{"id":"user1"}, "text": test_message}
        r2 = requests.post(send_url, headers=headers, json=payload)
        if r2.status_code not in (200, 201):
            return False, f"send failed: {r2.status_code} {r2.text}"
        get_url = f"https://directline.botframework.com/v3/directline/conversations/{conv_id}/activities"
        for _ in range(5):
            r3 = requests.get(get_url, headers=headers)
            if r3.status_code != 200:
                time.sleep(0.5); continue
            acts = r3.json().get("activities", [])
            bot_msgs = [a for a in acts if a.get("from",{}).get("id","").lower() != "user1" and a.get("type")=="message"]
            if bot_msgs:
                txts = [norm(a.get("text","")) for a in bot_msgs if a.get("text")]
                if txts:
                    return True, txts[-1][:500]
            time.sleep(0.6)
        return False, "no bot reply"
    except Exception as e:
        return False, f"error: {e}"

# ===================== Streamlit UI =====================
st.set_page_config(page_title="ExcelæŠ½å‡ºãƒ„ãƒ¼ãƒ«", page_icon="ğŸ§¾", layout="wide")
# ã‚¿ã‚¤ãƒˆãƒ«ã¯è¡¨ç¤ºã—ãªã„ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼è¦æœ›ï¼‰

with st.sidebar:
    st.subheader("ExcelæŠ½å‡ºã®å¿…é ˆé …ç›®")
    require_lotno = st.checkbox("Lot No.ã‚’å¿…é ˆã«ã™ã‚‹", value=True)
    require_exp   = st.checkbox("æœ‰åŠ¹æœŸé™ã‚’å¿…é ˆã«ã™ã‚‹", value=True)

    st.subheader("Copiloté€£æºãƒ†ã‚¹ãƒˆï¼ˆDirect Lineï¼‰")
    directline_secret = st.text_input("Direct Line ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆï¼ˆæ—¢å®šã®ãƒœãƒƒãƒˆï¼‰", type="password")
    test_text = st.text_input("ãƒ†ã‚¹ãƒˆé€ä¿¡ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸", value="ping")
    if st.button("Copilot æ¥ç¶šãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"):
        if not directline_secret:
            st.error("Direct Line ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        else:
            ok, msg = copilot_directline_test(directline_secret, test_message=test_text)
            if ok:
                st.success(f"âœ… é€£æºOKï¼ˆå¿œç­”ï¼‰ï¼š{msg}")
            else:
                st.error(f"âŒ é€£æºNGï¼š{msg}")

st.markdown("### 1) å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆExcelï¼è¤‡æ•°å¯ã€â˜…1å›ã«ã¤ãæœ€å¤§8ãƒ•ã‚¡ã‚¤ãƒ«ã¾ã§ï¼‰")
xlsx_inputs = st.file_uploader("Excelï¼ˆã‚·ãƒ¼ãƒˆè‡ªå‹•é¸æŠï¼šç·¨é›†ç”¨ï¼æœ€æ–°æ—¥ä»˜ï¼ãã®ä»–ã€ç¢ºèªç³»ã¯é™¤å¤–ï¼‰", type=["xlsx"], accept_multiple_files=True)

st.markdown("### 2) è¿½è¨˜å…ˆExcelï¼ˆæœªæŒ‡å®šãªã‚‰æ–°è¦ä½œæˆã—ã¦DLå¯ï¼‰")
out_book = st.file_uploader("æ—¢å­˜Excelï¼ˆâ€œç·¨é›†ç”¨/å“åã”ã¨/å·¥ç¨‹ã”ã¨/å“åãƒã‚¹ã‚¿â€ã‚’å«ã‚€æƒ³å®šï¼‰", type=["xlsx"])

st.markdown("---")
run = st.button("â–¶ ãƒ‡ãƒ¼ã‚¿æŠ½å‡º")

# çŠ¶æ…‹
if "rows_all" not in st.session_state: st.session_state.rows_all=[]
if "problems" not in st.session_state: st.session_state.problems=[]
if "updated_excel_bytes" not in st.session_state: st.session_state.updated_excel_bytes=None

if run:
    st.session_state.rows_all=[]; st.session_state.problems=[]; st.session_state.updated_excel_bytes=None

    # -------- Excelå‡¦ç†ã®ã¿ --------
    if xlsx_inputs:
        for xf in xlsx_inputs:
            try:
                xbytes=xf.read()
                xls=pd.ExcelFile(io.BytesIO(xbytes))
                target_sheet, reason = choose_target_sheet(xls.sheet_names)
                df=pd.read_excel(io.BytesIO(xbytes), sheet_name=target_sheet, header=None)

                koutei, lot = extract_koutei_lot_from_sheet(df)
                hmap=detect_header(df, scan_rows=60)
                if not hmap:
                    st.session_state.problems.append(f"{xf.name}: ãƒ˜ãƒƒãƒ€æ¤œå‡ºå¤±æ•—ï¼ˆ{target_sheet} / ç†ç”±: {reason}ï¼‰")
                    continue

                # ãƒ•ã‚¡ã‚¤ãƒ«åã«ã€Œè¿”åº«ã€ã‚’å«ã‚€å ´åˆã€æ‰•å‡ºæ•°ã‚’ãƒã‚¤ãƒŠã‚¹ç¬¦å·ã§å–ã‚Šè¾¼ã‚€
                base_name = xf.name.rsplit(".", 1)[0]
                qty_sign = -1 if is_henko_from_name(base_name) else 1

                rows, rej = parse_excel_table(
                    df, hmap, koutei or "", lot or "",
                    file_label=base_name,
                    qty_sign=qty_sign,
                    require_lotno=require_lotno,
                    require_exp=require_exp,
                )
                st.session_state.rows_all.extend(rows)
                if not rows:
                    st.session_state.problems.append(
                        f"{xf.name}: æ˜ç´°0ä»¶ï¼ˆ{target_sheet} / {reason} / æ‹’å¦å†…è¨³: {rej}ï¼‰"
                    )
                else:
                    bad = {k:v for k,v in rej.items() if v>0}
                    if bad:
                        st.info(f"{xf.name}ï¼ˆ{target_sheet}ï¼‰ã§ã‚¹ã‚­ãƒƒãƒ—: {bad}")
            except Exception as e:
                st.session_state.problems.append(f"{xf.name}: è§£æã‚¨ãƒ©ãƒ¼: {e}")

    total=len(st.session_state.rows_all)
    if st.session_state.problems:
        st.warning("ä¸€éƒ¨ã§å•é¡Œ:\n- " + "\n- ".join(st.session_state.problems))
    if total==0:
        st.error("æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿è¡Œã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
    else:
        st.success(f"åˆè¨ˆ {total} è¡Œã‚’æŠ½å‡ºã—ã¾ã—ãŸã€‚")

    # -------- â€œç·¨é›†ç”¨â€è¿½è¨˜ï¼‹ãƒ¬ãƒãƒ¼ãƒˆå†ä½œæˆ --------
    try:
        base_bytes = out_book.getvalue() if out_book else None
        updated = update_workbook_with_rows(base_bytes, st.session_state.rows_all, sheet_name="ç·¨é›†ç”¨")
        st.session_state.updated_excel_bytes = updated
        st.info("ã€ç·¨é›†ç”¨ã€ã¸è¿½è¨˜ã—ã€ã€å“åã”ã¨ã€ã€å·¥ç¨‹ã”ã¨ã€ã‚’æœ€æ–°åŒ–ã—ã¾ã—ãŸã€‚")
    except Exception as e:
        st.error(f"Excelã®æ›´æ–°ã«å¤±æ•—: {e}")

# ===================== ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ =====================
st.markdown("### æŠ½å‡ºçµæœï¼ˆå…ˆé ­300è¡Œï¼‰")
if st.session_state.rows_all:
    df_out = pd.DataFrame(st.session_state.rows_all, columns=HEADERS)[:300]
    st.dataframe(df_out, use_container_width=True)

st.markdown("### æ›´æ–°æ¸ˆã¿Excelã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
if st.session_state.updated_excel_bytes:
    st.download_button(
        "ğŸ“¥ æ›´æ–°æ¸ˆã¿Excelã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=st.session_state.updated_excel_bytes,
        file_name=f"updated_{int(time.time())}.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        use_container_width=True,
    )
